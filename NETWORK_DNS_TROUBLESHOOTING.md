# GitLab Runner DinD 网络与 DNS 问题排查

## 问题背景

在 Kubernetes 集群中配置 GitLab Runner 使用 Docker-in-Docker (DinD) 进行镜像构建时，遇到 DNS 解析失败问题，导致无法拉取基础镜像。

本文档详细分析 Kubernetes 网络架构、各层级之间的通信路径、以及 DinD 场景下的网络流量走向。

---

## 一、Kubernetes 网络架构深度解析

### 1.1 网络层级总览

```
┌────────────────────────────────────────────────────────────────┐
│                     物理/虚拟化层 (Layer 0)                      │
│  阿里云私有化部署 VPC                                             │
│  CIDR: 10.0.0.0/16                                           │
└────────────────────┬───────────────────────────────────────────┘
                     │
┌────────────────────┴───────────────────────────────────────────┐
│                   Kubernetes 集群层 (Layer 1)                    │
│  Control Plane + Worker Nodes                                  │
│  节点网络: 10.202.3.0/24                                         │
└────────────────────┬───────────────────────────────────────────┘
                     │
         ┌───────────┴───────────┐
         │                       │
┌────────┴─────────┐  ┌─────────┴────────┐
│  Service 网络     │  │   Pod 网络        │
│  (Layer 2)       │  │   (Layer 3)      │
│  172.21.0.0/16   │  │   172.24.0.0/16  │
└──────────────────┘  └─────────┬────────┘
                                │
                    ┌───────────┴───────────┐
                    │   Container 网络       │
                    │   (Layer 4)           │
                    │   共享 Pod 网络命名空间  │
                    └───────────┬───────────┘
                                │
                    ┌───────────┴────────────┐
                    │  Docker-in-Docker      │
                    │  (Layer 5)             │
                    │  虚拟化的 Docker 网络    │
                    └────────────────────────┘
```

### 1.2 Layer 0: 物理网络层（VPC/数据中心网络）

#### 网络拓扑

```
┌─────────────────────────────────────────────────────────────────────┐
│                    阿里云私有化部署 VPC                               │
│                    CIDR: 10.0.0.0/16                              │
│                                                                     │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐             │
│  │ Master Node  │  │ Worker Node1 │  │ Worker Node2 │             │
│  │ 192.168.1.100 │  │ 192.168.1.101 │  │ 192.168.1.102 │             │
│  │              │  │              │  │              │             │
│  │ etcd         │  │ kubelet      │  │ kubelet      │             │
│  │ kube-api     │  │ kube-proxy   │  │ kube-proxy   │             │
│  │ scheduler    │  │ container    │  │ container    │             │
│  │ controller   │  │ runtime      │  │ runtime      │             │
│  └──────┬───────┘  └──────┬───────┘  └──────┬───────┘             │
│         │                 │                 │                     │
│         └─────────────────┴─────────────────┘                     │
│                    │                                               │
│                    │ 物理网络交换（交换机/路由器）                   │
│                    │                                               │
│  ┌─────────────────┴──────────────────────────────────┐           │
│  │                VPC 网络服务                          │           │
│  │  - DNS: 10.0.0.2, 10.1.0.251, 10.1.0.252    │           │
│  │  - NAT Gateway (出站访问公网)                       │           │
│  │  - Security Group (防火墙规则)                     │           │
│  └────────────────────────────────────────────────────┘           │
└─────────────────────────────────────────────────────────────────────┘
```

#### 关键特性

| 特性 | 说明 |
|------|------|
| **IP 地址空间** | 10.0.0.0/16 (65536 个 IP) |
| **节点 CIDR** | 10.202.3.0/24 (256 个 IP) |
| **DNS 服务器** | 10.0.0.2 (VPC DNS)<br>10.1.0.251 (主)<br>10.1.0.252 (备) |
| **网络隔离** | 通过 Security Group 控制 |
| **出站路由** | 通过 NAT Gateway 访问公网 |

#### 网络初始状态

```bash
# 节点的网络配置
# /etc/resolv.conf (节点级别)
nameserver 10.1.0.251
nameserver 10.1.0.252
nameserver 10.0.0.2
search localdomain

# 路由表 (节点级别)
# ip route show
default via 10.202.3.1 dev eth0
10.0.0.0/16 dev eth0 proto kernel scope link src 192.168.1.101
172.24.0.0/16 via 192.168.1.101 dev flannel.1  # Pod 网络路由
```

---

### 1.3 Layer 1: Kubernetes 集群网络层

#### 1.3.1 Control Plane 组件

```
┌─────────────────────────────────────────────────────────────┐
│                  Master Node (192.168.1.100)                 │
│                                                             │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  kube-apiserver                                     │   │
│  │  监听: 192.168.1.100:6443                            │   │
│  │  职责: 对外提供 Kubernetes API                       │   │
│  └─────────────────────────────────────────────────────┘   │
│                           │                                 │
│  ┌────────────────────────┴────────────────────────────┐   │
│  │  etcd                                               │   │
│  │  监听: 127.0.0.1:2379                               │   │
│  │  职责: 存储集群状态                                  │   │
│  └─────────────────────────────────────────────────────┘   │
│                           │                                 │
│  ┌────────────────────────┴────────────────────────────┐   │
│  │  kube-scheduler                                     │   │
│  │  职责: Pod 调度到节点                                │   │
│  └─────────────────────────────────────────────────────┘   │
│                           │                                 │
│  ┌────────────────────────┴────────────────────────────┐   │
│  │  kube-controller-manager                            │   │
│  │  职责: 运行控制器（Deployment、Service 等）          │   │
│  └─────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────┘
```

#### 1.3.2 Worker Node 组件

```
┌─────────────────────────────────────────────────────────────┐
│              Worker Node (192.168.1.101)                     │
│                                                             │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  kubelet                                            │   │
│  │  监听: 192.168.1.101:10250                           │   │
│  │  职责:                                              │   │
│  │  - 管理 Pod 生命周期                                │   │
│  │  - 与 API Server 通信                               │   │
│  │  - 调用 CNI 插件配置 Pod 网络                       │   │
│  │  - 调用容器运行时创建容器                            │   │
│  └─────────────────────────────────────────────────────┘   │
│                           │                                 │
│  ┌────────────────────────┴────────────────────────────┐   │
│  │  kube-proxy                                         │   │
│  │  模式: iptables / IPVS                              │   │
│  │  职责:                                              │   │
│  │  - 实现 Service 负载均衡                            │   │
│  │  - 管理 iptables/IPVS 规则                          │   │
│  │  - 实现 ClusterIP / NodePort / LoadBalancer        │   │
│  └─────────────────────────────────────────────────────┘   │
│                           │                                 │
│  ┌────────────────────────┴────────────────────────────┐   │
│  │  Container Runtime (containerd)                     │   │
│  │  Socket: /run/containerd/containerd.sock            │   │
│  │  职责:                                              │   │
│  │  - 镜像管理（拉取、存储）                            │   │
│  │  - 容器生命周期管理                                  │   │
│  │  - 容器网络命名空间创建                              │   │
│  └─────────────────────────────────────────────────────┘   │
│                           │                                 │
│  ┌────────────────────────┴────────────────────────────┐   │
│  │  CNI Plugin (Flannel/Calico)                        │   │
│  │  配置: /etc/cni/net.d/                              │   │
│  │  职责:                                              │   │
│  │  - 为 Pod 分配 IP 地址                              │   │
│  │  - 配置网络命名空间                                  │   │
│  │  - 设置路由规则                                     │   │
│  └─────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────┘
```

#### 1.3.3 网络通信流程

```
┌─────────────────────────────────────────────────────────────┐
│                    集群网络通信矩阵                           │
└─────────────────────────────────────────────────────────────┘

1. Node ←→ API Server
   192.168.1.101:随机端口 → 192.168.1.100:6443
   协议: HTTPS
   用途: kubelet 上报节点状态、获取 Pod 规范

2. Node ←→ Node
   192.168.1.101 ←→ 192.168.1.102
   协议: VXLAN (Flannel) / BGP (Calico)
   用途: Pod 跨节点通信的隧道

3. Master ←→ Master (HA 模式)
   192.168.1.100 ←→ 10.202.3.105
   协议: etcd 集群同步 (2379, 2380)
   用途: etcd 数据复制

4. External ←→ API Server
   外部客户端 → 192.168.1.100:6443
   协议: HTTPS
   用途: kubectl 命令行工具访问

5. Node ←→ External (镜像拉取)
   192.168.1.101 → 外部镜像仓库
   协议: HTTPS (443)
   路径: Node → NAT Gateway → 公网
   用途: 拉取容器镜像
```

---

### 1.4 Layer 2: Service 网络层 (ClusterIP)

#### 1.4.1 Service 网络模型

```
┌─────────────────────────────────────────────────────────────┐
│                Service 网络 (172.21.0.0/16)                  │
│                                                             │
│  特点:                                                       │
│  - 虚拟 IP (VIP)，不绑定任何网卡                             │
│  - 由 kube-proxy 通过 iptables/IPVS 规则实现                 │
│  - 只在集群内部可访问                                        │
│  - 提供负载均衡到后端 Pod                                    │
└─────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────┐
│  Service: gitlab-runner                                     │
│  ClusterIP: 172.21.5.123                                    │
│  Port: 9252                                                 │
│                                                             │
│  Endpoints:                                                 │
│  - 172.24.1.10:9252  (runner-pod-1)                        │
│  - 172.24.2.15:9252  (runner-pod-2)                        │
│  - 172.24.3.20:9252  (runner-pod-3)                        │
└─────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────┐
│  Service: kube-dns (CoreDNS)                                │
│  ClusterIP: 10.96.0.10                                     │
│  Port: 53 (DNS)                                             │
│                                                             │
│  Endpoints:                                                 │
│  - 172.24.0.5:53  (coredns-pod-1)                          │
│  - 172.24.0.6:53  (coredns-pod-2)                          │
└─────────────────────────────────────────────────────────────┘
```

#### 1.4.2 kube-proxy 实现原理 (iptables 模式)

```bash
# Service 创建后，kube-proxy 在每个节点上添加 iptables 规则

# 1. PREROUTING 链 - 捕获 Service IP 的流量
-A PREROUTING -m comment --comment "kubernetes service portals" -j KUBE-SERVICES

# 2. KUBE-SERVICES 链 - 匹配 Service ClusterIP
-A KUBE-SERVICES -d 10.96.0.10/32 -p udp -m udp --dport 53 \
   -j KUBE-SVC-TCOU7JCQXEZGVUNU

# 3. KUBE-SVC-* 链 - 负载均衡到 Endpoints
-A KUBE-SVC-TCOU7JCQXEZGVUNU -m statistic --mode random --probability 0.5 \
   -j KUBE-SEP-ENDPOINT1
-A KUBE-SVC-TCOU7JCQXEZGVUNU \
   -j KUBE-SEP-ENDPOINT2

# 4. KUBE-SEP-* 链 - DNAT 到实际 Pod IP
-A KUBE-SEP-ENDPOINT1 -p udp -m udp \
   -j DNAT --to-destination 172.24.0.5:53
-A KUBE-SEP-ENDPOINT2 -p udp -m udp \
   -j DNAT --to-destination 172.24.0.6:53
```

#### 1.4.3 Service 类型与网络行为

| Service 类型 | ClusterIP | 节点端口 | 外部可访问 | 使用场景 |
|-------------|-----------|---------|-----------|---------|
| **ClusterIP** | 172.21.x.x | 无 | ❌ | 集群内部服务 |
| **NodePort** | 172.21.x.x | 30000-32767 | ✅ | 暴露服务到节点 |
| **LoadBalancer** | 172.21.x.x | 30000-32767 | ✅ | 云厂商负载均衡器 |
| **ExternalName** | 无 | 无 | ❌ | DNS CNAME 别名 |

**NodePort 示例**：
```yaml
apiVersion: v1
kind: Service
metadata:
  name: calculator
spec:
  type: NodePort
  ports:
  - port: 30194      # Service 端口
    targetPort: 30194 # Pod 端口
    nodePort: 30194   # 节点端口
  selector:
    app: calculator

# 访问路径:
# 外部 → 192.168.1.101:30194 (任意节点 IP)
#      → iptables DNAT
#      → 172.24.x.x:30194 (Pod IP)
```

---

### 1.5 Layer 3: Pod 网络层

#### 1.5.1 Pod 网络模型

```
┌─────────────────────────────────────────────────────────────┐
│                Pod 网络 (172.24.0.0/16)                      │
│                                                             │
│  特点:                                                       │
│  - 每个 Pod 有独立的 IP 地址                                │
│  - 同一个 Pod 内的所有容器共享网络命名空间                    │
│  - Pod IP 在集群内全局可达                                  │
│  - Pod 重启后 IP 会变化                                     │
└─────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────┐
│                   Pod CIDR 分配                              │
│                                                             │
│  节点 1 (192.168.1.101):  172.24.1.0/24                      │
│  节点 2 (192.168.1.102):  172.24.2.0/24                      │
│  节点 3 (192.168.1.103):  172.24.3.0/24                      │
│  ...                                                        │
└─────────────────────────────────────────────────────────────┘
```

#### 1.5.2 CNI 插件网络配置流程

```
Pod 创建流程:
┌──────────────────────────────────────────────────────────────┐
│ 1. API Server 接收 Pod 创建请求                               │
│    POST /api/v1/namespaces/gitlab/pods                      │
└───────────┬──────────────────────────────────────────────────┘
            │
            ↓
┌───────────┴──────────────────────────────────────────────────┐
│ 2. Scheduler 选择节点 (192.168.1.101)                         │
│    基于资源请求、亲和性、污点容忍等                            │
└───────────┬──────────────────────────────────────────────────┘
            │
            ↓
┌───────────┴──────────────────────────────────────────────────┐
│ 3. Kubelet 监听到 Pod 分配事件                                │
│    通过 Watch API 实时获取                                    │
└───────────┬──────────────────────────────────────────────────┘
            │
            ↓
┌───────────┴──────────────────────────────────────────────────┐
│ 4. 创建 Pod Sandbox (Pause 容器)                             │
│    $ crictl run pause_config.json pod_config.json            │
│    - Pause 容器持有网络命名空间                               │
│    - 其他容器共享此命名空间                                   │
└───────────┬──────────────────────────────────────────────────┘
            │
            ↓
┌───────────┴──────────────────────────────────────────────────┐
│ 5. 调用 CNI 插件配置网络                                      │
│    $ /opt/cni/bin/flannel < network_config.json              │
│                                                              │
│    CNI 插件执行:                                              │
│    a) 从 IPAM 获取 IP: 172.24.1.100/24                       │
│    b) 创建 veth pair:                                        │
│       - veth0 (容器内) → eth0                                │
│       - veth1 (主机侧) → cni0 网桥                           │
│    c) 设置路由规则:                                           │
│       - default via 172.24.1.1 dev eth0                     │
│    d) 配置 DNS (/etc/resolv.conf):                           │
│       - nameserver 10.96.0.10 (kube-dns)                   │
│       - search gitlab.svc.cluster.local ...                 │
└───────────┬──────────────────────────────────────────────────┘
            │
            ↓
┌───────────┴──────────────────────────────────────────────────┐
│ 6. 启动业务容器 (加入 Pod 网络命名空间)                        │
│    $ crictl create <container-config> <pod-sandbox-id>       │
│    使用 --network=container:<pause-container-id>             │
└──────────────────────────────────────────────────────────────┘
```

#### 1.5.3 Pod 网络命名空间详解

```
┌──────────────────────────────────────────────────────────────┐
│                Job Pod Network Namespace                     │
│                (所有容器共享)                                  │
│                                                              │
│  Network Interfaces:                                         │
│  ┌────────────────────────────────────────────────────┐     │
│  │  lo (loopback)                                     │     │
│  │  inet 127.0.0.1/8                                  │     │
│  │  用途: 容器间本地通信 (docker:2375)                 │     │
│  └────────────────────────────────────────────────────┘     │
│                                                              │
│  ┌────────────────────────────────────────────────────┐     │
│  │  eth0 (veth pair 的一端)                           │     │
│  │  inet 172.24.1.100/24                              │     │
│  │  用途: 与外部通信                                   │     │
│  └────────────────────────────────────────────────────┘     │
│                                                              │
│  Routing Table:                                              │
│  ┌────────────────────────────────────────────────────┐     │
│  │  default via 172.24.1.1 dev eth0                   │     │
│  │  172.24.0.0/16 dev eth0 scope link                 │     │
│  │  127.0.0.0/8 dev lo scope host                     │     │
│  └────────────────────────────────────────────────────┘     │
│                                                              │
│  /etc/resolv.conf:                                           │
│  ┌────────────────────────────────────────────────────┐     │
│  │  nameserver 10.0.0.2                             │     │
│  │  nameserver 10.1.0.251                           │     │
│  │  nameserver 10.1.0.252                           │     │
│  │  search gitlab.svc.cluster.local ...               │     │
│  │  options ndots:2                                   │     │
│  └────────────────────────────────────────────────────┘     │
│                                                              │
│  /etc/hosts:                                                 │
│  ┌────────────────────────────────────────────────────┐     │
│  │  127.0.0.1 localhost                               │     │
│  │  127.0.0.1 docker    # Service alias 注入         │     │
│  │  172.24.1.100 runner-xxx-xxx                       │     │
│  └────────────────────────────────────────────────────┘     │
│                                                              │
│  容器视图:                                                    │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐      │
│  │   Helper     │  │    Build     │  │     DinD     │      │
│  │  Container   │  │  Container   │  │  Container   │      │
│  │              │  │              │  │              │      │
│  │  共享以上所有网络资源                                │      │
│  └──────────────┘  └──────────────┘  └──────────────┘      │
└──────────────────────────────────────────────────────────────┘
```

---

### 1.6 Layer 4: Container 网络层

#### 1.6.1 容器与 Pod 网络的关系

```
┌──────────────────────────────────────────────────────────────┐
│                   同一 Pod 内的容器                            │
│                                                              │
│  ┌──────────────────────┐  ┌──────────────────────┐         │
│  │  Build Container     │  │  DinD Container      │         │
│  │                      │  │                      │         │
│  │  进程 PID: 12345     │  │  进程 PID: 12390     │         │
│  │  挂载命名空间: 独立   │  │  挂载命名空间: 独立   │         │
│  │  PID 命名空间: 独立  │  │  PID 命名空间: 独立  │         │
│  │  ✅ 网络命名空间: 共享 │  │  ✅ 网络命名空间: 共享 │         │
│  │  ✅ IPC 命名空间: 共享 │  │  ✅ IPC 命名空间: 共享 │         │
│  │                      │  │                      │         │
│  │  $ ip addr show      │  │  $ ip addr show      │         │
│  │  eth0: 172.24.1.100  │  │  eth0: 172.24.1.100  │         │
│  │  lo: 127.0.0.1       │  │  lo: 127.0.0.1       │         │
│  │  (完全相同的输出)     │  │  (完全相同的输出)     │         │
│  └──────────────────────┘  └──────────────────────┘         │
│             │                         │                     │
│             └───────────┬─────────────┘                     │
│                         │                                   │
│            共享相同的 Network Stack                           │
│            - 相同的 IP 地址                                  │
│            - 相同的网卡                                      │
│            - 相同的路由表                                    │
│            - 相同的 iptables 规则                            │
│            - 相同的 /etc/hosts                              │
│            - 相同的 /etc/resolv.conf                        │
└──────────────────────────────────────────────────────────────┘
```

#### 1.6.2 容器间通信机制

**场景 1: 同一 Pod 内容器通信（Build → DinD）**
```
Build Container                   DinD Container
     │                                 │
     │ docker -H tcp://docker:2375 info
     │                                 │
     ├─→ 解析 "docker"                 │
     │   查询 /etc/hosts               │
     │   docker → 127.0.0.1            │
     │                                 │
     ├─→ TCP 连接 127.0.0.1:2375       │
     │   （本地回环）                   │
     │   ─────────────────────────────→│
     │                                 │ dockerd 监听 0.0.0.0:2375
     │                                 │ 接收请求
     │                                 │
     │   ←─────────────────────────────│
     │   返回 Docker 信息               │
     │                                 │
     ↓                                 ↓

流量路径:
应用层 → TCP 栈 → Loopback 接口 (内核内部) → TCP 栈 → 应用层
不经过任何物理网卡，完全在内核内存中传输
延迟: < 0.1ms
```

**场景 2: 不同 Pod 之间通信**
```
Pod A (172.24.1.10)              Pod B (172.24.2.20)
Node 1 (192.168.1.101)            Node 2 (192.168.1.102)

Container A                      Container B
     │                                │
     ├─→ 发送数据到 172.24.2.20:80     │
     │                                │
     ↓ eth0 (Pod A 网络命名空间)       │
     ↓                                │
veth pair → cni0 网桥 (Node 1)       │
     ↓                                │
flannel.1 (VXLAN 隧道接口)           │
     ↓                                │
封装: UDP + VXLAN + IP + 原始数据     │
     ↓                                │
物理网卡 eth0 (Node 1)               │
     │                                │
     ├─→ 192.168.1.101 → 192.168.1.102 │
     │   (节点间物理网络)               │
     │                                │
     │   ─────────────────────────────→│
     │                                │
     │                    物理网卡 eth0 (Node 2)
     │                                ↓
     │                    flannel.1 解封装
     │                                ↓
     │                    cni0 网桥 (Node 2)
     │                                ↓
     │                    veth pair
     │                                ↓
     │                    eth0 (Pod B 网络命名空间)
     │                                ↓
     │                           Container B
     │   ←─────────────────────────────│
     │   返回响应（反向路径）            │
     ↓                                ↓

流量路径:
Container A → veth → cni0 → flannel.1 → eth0 (Node 1)
  → 网络 → eth0 (Node 2) → flannel.1 → cni0 → veth → Container B

延迟: 1-2ms (同节点) / 2-5ms (跨节点)
```

---

### 1.7 Layer 5: Docker-in-Docker 网络层

#### 1.7.1 DinD 的特殊网络架构

```
┌──────────────────────────────────────────────────────────────┐
│                       Job Pod                                │
│                   Pod IP: 172.24.1.100                       │
│                                                              │
│  ┌──────────────────────────────────────────────────────┐   │
│  │            DinD Container                            │   │
│  │            (Service Container)                       │   │
│  │                                                      │   │
│  │  ┌────────────────────────────────────────────────┐ │   │
│  │  │   dockerd 守护进程                              │ │   │
│  │  │   监听: 0.0.0.0:2375 (TCP)                      │ │   │
│  │  │   监听: /var/run/docker.sock (Unix Socket)     │ │   │
│  │  └────────────────────────────────────────────────┘ │   │
│  │                       │                              │   │
│  │                       │ 创建临时容器                  │   │
│  │                       ↓                              │   │
│  │  ┌────────────────────────────────────────────────┐ │   │
│  │  │   虚拟 Docker 网络 (docker0 网桥)              │ │   │
│  │  │   CIDR: 172.17.0.0/16                          │ │   │
│  │  │                                                │ │   │
│  │  │   ⚠️  这是 DinD 容器内部的虚拟网络              │ │   │
│  │  │   ⚠️  与 Pod 网络隔离                          │ │   │
│  │  └────────────────────────────────────────────────┘ │   │
│  │                       │                              │   │
│  │         执行 RUN 指令时创建的临时容器                  │   │
│  │                       ↓                              │   │
│  │  ┌────────────────────────────────────────────────┐ │   │
│  │  │   临时容器 (RUN pip install)                    │ │   │
│  │  │   IP: 172.17.0.2 (DinD 内部分配)               │ │   │
│  │  │                                                │ │   │
│  │  │   网络命名空间: 独立 (不同于 Pod)               │ │   │
│  │  │                                                │ │   │
│  │  │   DNS 配置:                                    │ │   │
│  │  │   - 如果 dockerd 启动时有 --dns 参数:          │ │   │
│  │  │     nameserver <--dns 指定的值>                │ │   │
│  │  │   - 如果没有 --dns 参数:                       │ │   │
│  │  │     继承 DinD 容器的 /etc/resolv.conf          │ │   │
│  │  │                                                │ │   │
│  │  │   路由:                                        │ │   │
│  │  │   default via 172.17.0.1 dev eth0             │ │   │
│  │  │   (网关是 DinD 的 docker0 网桥)                │ │   │
│  │  └────────────────────────────────────────────────┘ │   │
│  └──────────────────────────────────────────────────────┘   │
└──────────────────────────────────────────────────────────────┘
```

#### 1.7.2 DinD 网络流量的三层路径

```
┌──────────────────────────────────────────────────────────────┐
│  临时容器访问外网的完整路径                                     │
│  (例如: RUN pip install flask → 访问 pypi.org)                │
└──────────────────────────────────────────────────────────────┘

Layer 5: DinD 临时容器
┌────────────────────────────────────────────────────┐
│ 临时容器 (172.17.0.2)                              │
│ $ pip install flask                                │
│ 发起 DNS 查询: pypi.org                            │
│ 读取 /etc/resolv.conf:                             │
│   - 如有 --dns: 使用 --dns 指定的 DNS              │
│   - 如无 --dns: 使用 10.0.0.2 (继承自 DinD)     │
└───────────────────┬────────────────────────────────┘
                    │ DNS 查询
                    ↓
Layer 5 → Layer 4: DinD 容器网络命名空间
┌────────────────────────────────────────────────────┐
│ docker0 网桥 (172.17.0.1)                          │
│ NAT 规则: 172.17.0.0/16 → Pod IP (172.24.1.100)   │
│ iptables MASQUERADE:                               │
│   -t nat -A POSTROUTING -s 172.17.0.0/16          │
│   -j MASQUERADE                                    │
│ (源 IP 替换为 Pod IP)                              │
└───────────────────┬────────────────────────────────┘
                    │ SNAT: 172.17.0.2 → 172.24.1.100
                    ↓
Layer 4 → Layer 3: Pod 网络命名空间
┌────────────────────────────────────────────────────┐
│ Pod eth0 (172.24.1.100)                            │
│ 路由: default via 172.24.1.1                       │
└───────────────────┬────────────────────────────────┘
                    │
                    ↓
Layer 3 → Layer 1: Node 网络
┌────────────────────────────────────────────────────┐
│ cni0 网桥 (Node 1)                                 │
│ 路由: 0.0.0.0/0 via 10.202.3.1 (默认网关)          │
│ iptables MASQUERADE:                               │
│   -t nat -A POSTROUTING -s 172.24.0.0/16          │
│   -j MASQUERADE                                    │
│ (源 IP 再次替换为节点 IP)                          │
└───────────────────┬────────────────────────────────┘
                    │ SNAT: 172.24.1.100 → 192.168.1.101
                    ↓
Layer 1 → Layer 0: 物理网络
┌────────────────────────────────────────────────────┐
│ 节点物理网卡 (192.168.1.101)                        │
│ → VPC NAT Gateway                                  │
│ → 公网 (访问 pypi.org)                             │
└────────────────────────────────────────────────────┘

返回路径（反向）:
外网响应 → NAT Gateway (DNAT) → 节点 IP → iptables 反向 NAT
→ Pod IP → DinD docker0 反向 NAT → 临时容器
```

#### 1.7.3 DinD 的两种 DNS 配置对比

```
┌──────────────────────────────────────────────────────────────┐
│  配置 1: 不使用 --dns 参数（推荐）                             │
└──────────────────────────────────────────────────────────────┘

# .gitlab-ci.yml
services:
  - name: docker:dind
    command:
      - "--tls=false"
      # 没有 --dns 参数

# 效果:
┌─────────────────────────────────────────────────────────┐
│ DinD 容器 /etc/resolv.conf (来自 Pod DNS 配置)          │
│ nameserver 10.0.0.2                                   │
│ nameserver 10.1.0.251                                 │
│ search gitlab.svc.cluster.local ...                    │
└────────────────────┬────────────────────────────────────┘
                     │ dockerd 自己的 DNS
                     │ ✅ 拉取镜像时使用此配置
                     ↓
              ┌──────────────┐
              │ FROM python  │ ← DNS 解析成功
              └──────────────┘
                     │
                     │ dockerd 创建临时容器时
                     │ 继承 DinD 的 /etc/resolv.conf
                     ↓
┌─────────────────────────────────────────────────────────┐
│ 临时容器 /etc/resolv.conf (继承自 DinD)                  │
│ nameserver 10.0.0.2                                   │
│ nameserver 10.1.0.251                                 │
│ search gitlab.svc.cluster.local ...                    │
└────────────────────┬────────────────────────────────────┘
                     │ RUN 指令内的 DNS
                     ↓
              ┌──────────────┐
              │ RUN pip      │ ← DNS 解析成功
              │ install flask│
              └──────────────┘

优点:
- 配置统一，易于管理
- 支持 K8s 服务发现 (search domains)
- 临时容器自动继承正确的 DNS

缺点:
- 临时容器与 DinD 使用相同的 DNS


┌──────────────────────────────────────────────────────────────┐
│  配置 2: 使用 --dns 参数                                       │
└──────────────────────────────────────────────────────────────┘

# .gitlab-ci.yml
services:
  - name: docker:dind
    command:
      - "--tls=false"
      - "--dns=8.8.8.8"  # 指定临时容器使用的 DNS

# 效果:
┌─────────────────────────────────────────────────────────┐
│ DinD 容器 /etc/resolv.conf (来自 Pod DNS 配置)          │
│ nameserver 10.0.0.2                                   │
│ nameserver 10.1.0.251                                 │
│ search gitlab.svc.cluster.local ...                    │
└────────────────────┬────────────────────────────────────┘
                     │ dockerd 自己的 DNS
                     │ ✅ 拉取镜像时使用此配置
                     ↓
              ┌──────────────┐
              │ FROM python  │ ← DNS 解析成功
              └──────────────┘
                     │
                     │ dockerd 创建临时容器时
                     │ 使用 --dns 参数指定的 DNS
                     ↓
┌─────────────────────────────────────────────────────────┐
│ 临时容器 /etc/resolv.conf (由 dockerd 设置)              │
│ nameserver 8.8.8.8  ← 来自 --dns 参数                   │
│ (没有 search domains)                                   │
└────────────────────┬────────────────────────────────────┘
                     │ RUN 指令内的 DNS
                     ↓
              ┌──────────────┐
              │ RUN pip      │ ← 使用 8.8.8.8 解析
              │ install flask│
              └──────────────┘

优点:
- 临时容器可以使用不同的 DNS (如公网 DNS)
- 适用于 RUN 指令需要访问特殊域名的场景

缺点:
- 配置分散（Pod DNS 和 --dns 参数）
- 临时容器无法使用 K8s 服务发现
- 需要确保 Pod 能访问 --dns 指定的 DNS 服务器
```

---

## 二、数据包完整流转路径分析

### 2.1 入站流量：外部 → Pod

#### 场景：用户访问 NodePort 服务

```
┌──────────────────────────────────────────────────────────────┐
│  外部用户访问: http://192.168.1.101:30194/                     │
└──────────────────────────────────────────────────────────────┘

Step 1: 数据包到达节点
┌────────────────────────────────────────────────────┐
│ 源: 客户端 IP (1.2.3.4:54321)                      │
│ 目标: 192.168.1.101:30194                           │
│ 协议: TCP SYN                                      │
└───────────────────┬────────────────────────────────┘
                    │ 到达节点物理网卡
                    ↓
Step 2: iptables PREROUTING 链处理
┌────────────────────────────────────────────────────┐
│ -A PREROUTING -j KUBE-SERVICES                     │
│                                                    │
│ -A KUBE-SERVICES -p tcp --dport 30194             │
│   -j KUBE-NODEPORTS                                │
│                                                    │
│ -A KUBE-NODEPORTS                                  │
│   -m comment --comment "calculator NodePort"       │
│   -j KUBE-SVC-CALCULATOR                           │
└───────────────────┬────────────────────────────────┘
                    │ 匹配 NodePort 规则
                    ↓
Step 3: Service 负载均衡
┌────────────────────────────────────────────────────┐
│ -A KUBE-SVC-CALCULATOR                             │
│   -m statistic --mode random --probability 0.5     │
│   -j KUBE-SEP-POD1                                 │
│ -A KUBE-SVC-CALCULATOR                             │
│   -j KUBE-SEP-POD2                                 │
└───────────────────┬────────────────────────────────┘
                    │ 选择 POD1 (50% 概率)
                    ↓
Step 4: DNAT 到 Pod IP
┌────────────────────────────────────────────────────┐
│ -A KUBE-SEP-POD1                                   │
│   -j DNAT --to-destination 172.24.1.50:30194      │
│                                                    │
│ 修改数据包:                                         │
│ 源: 1.2.3.4:54321                                  │
│ 目标: 172.24.1.50:30194 (Pod IP)                   │
└───────────────────┬────────────────────────────────┘
                    │ DNAT 完成
                    ↓
Step 5: 路由决策
┌────────────────────────────────────────────────────┐
│ $ ip route get 172.24.1.50                         │
│ 172.24.1.50 via 172.24.1.1 dev cni0                │
└───────────────────┬────────────────────────────────┘
                    │ 路由到 cni0 网桥
                    ↓
Step 6: 通过 veth pair 到达 Pod
┌────────────────────────────────────────────────────┐
│ cni0 网桥 → veth123abc (节点侧)                     │
│           → eth0 (Pod 侧)                          │
│           → Pod Network Namespace                  │
└───────────────────┬────────────────────────────────┘
                    │ 进入 Pod 网络命名空间
                    ↓
Step 7: 容器接收数据包
┌────────────────────────────────────────────────────┐
│ 容器内应用监听 0.0.0.0:30194                        │
│ 接收连接请求                                        │
│ 处理 HTTP 请求                                      │
└────────────────────────────────────────────────────┘

返回路径 (出站):
┌────────────────────────────────────────────────────┐
│ 容器应用 → eth0 (Pod) → veth → cni0               │
│ → iptables SNAT (恢复源 IP)                        │
│ → 节点网卡 → 客户端                                 │
└────────────────────────────────────────────────────┘
```

---

### 2.2 出站流量：Pod → 外部

#### 场景 1：Pod 访问外部服务（如拉取镜像）

```
┌──────────────────────────────────────────────────────────────┐
│  DinD 拉取镜像: registry.example.com             │
└──────────────────────────────────────────────────────────────┘

Step 1: DNS 解析
┌────────────────────────────────────────────────────┐
│ DinD 容器内 dockerd 进程                            │
│ 发起 DNS 查询: registry.example.com    │
│                                                    │
│ 读取 /etc/resolv.conf:                             │
│   nameserver 10.0.0.2                            │
└───────────────────┬────────────────────────────────┘
                    │ DNS 查询数据包
                    ↓
Step 2: DNS 查询出站
┌────────────────────────────────────────────────────┐
│ 源: 172.24.1.100:34567 (Pod IP)                    │
│ 目标: 10.0.0.2:53 (DNS 服务器)                   │
│ 协议: UDP                                          │
│ 查询: registry.example.com A 记录      │
└───────────────────┬────────────────────────────────┘
                    │ 离开 Pod
                    ↓
Step 3: 经过节点网络栈
┌────────────────────────────────────────────────────┐
│ Pod eth0 → veth → cni0 网桥 → 节点路由决策         │
│                                                    │
│ $ ip route get 10.0.0.2                          │
│ 10.0.0.2 via 10.202.3.1 dev eth0                │
│ (通过节点默认网关)                                  │
└───────────────────┬────────────────────────────────┘
                    │ 路由到节点物理网卡
                    ↓
Step 4: SNAT (源地址转换)
┌────────────────────────────────────────────────────┐
│ iptables POSTROUTING 链:                           │
│ -A POSTROUTING -s 172.24.0.0/16                    │
│   ! -o cni0                                        │
│   -j MASQUERADE                                    │
│                                                    │
│ 修改数据包:                                         │
│ 源: 192.168.1.101:34567 (节点 IP)                   │
│ 目标: 10.0.0.2:53                                │
└───────────────────┬────────────────────────────────┘
                    │ SNAT 完成
                    ↓
Step 5: 发送到 VPC 网络
┌────────────────────────────────────────────────────┐
│ 节点物理网卡 → VPC 交换机 → DNS 服务器             │
│ 10.0.0.2 响应: 203.0.113.10                     │
└───────────────────┬────────────────────────────────┘
                    │ DNS 响应返回
                    ↓
Step 6: DNS 响应回包
┌────────────────────────────────────────────────────┐
│ 目标: 192.168.1.101:34567                           │
│ → iptables 反向 SNAT (conntrack)                   │
│ → 目标恢复为: 172.24.1.100:34567                   │
│ → cni0 → veth → Pod eth0                          │
│ → dockerd 接收 DNS 响应                            │
└────────────────────────────────────────────────────┘

Step 7: HTTP 连接拉取镜像
┌────────────────────────────────────────────────────┐
│ dockerd 发起 HTTPS 连接:                            │
│ 源: 172.24.1.100:45678                             │
│ 目标: 203.0.113.10:443                            │
│                                                    │
│ 数据包路径 (与 DNS 查询相同):                       │
│ Pod → veth → cni0 → SNAT (192.168.1.101)           │
│ → 节点网卡 → VPC NAT Gateway → 公网               │
│ → 华为云镜像仓库 (203.0.113.10)                   │
└────────────────────────────────────────────────────┘
```

#### 场景 2：Pod 访问 Kubernetes Service

```
┌──────────────────────────────────────────────────────────────┐
│  Build 容器访问 GitLab: http://gitlab.gitlab.svc.cluster.local │
└──────────────────────────────────────────────────────────────┘

Step 1: DNS 解析 (Service 域名)
┌────────────────────────────────────────────────────┐
│ Build 容器发起 DNS 查询:                            │
│ gitlab.gitlab.svc.cluster.local                    │
│                                                    │
│ /etc/resolv.conf:                                  │
│   nameserver 10.0.0.2                            │
│   search gitlab.svc.cluster.local ...              │
│   options ndots:2                                  │
│                                                    │
│ 由于 "gitlab.gitlab.svc.cluster.local" 的 dots = 3│
│ 大于 ndots (2)，先作为绝对域名查询                  │
└───────────────────┬────────────────────────────────┘
                    │ DNS 查询
                    ↓
Step 2: DNS 查询被拦截
┌────────────────────────────────────────────────────┐
│ 因为 DNS 配置是 10.0.0.2 (VPC DNS)                │
│ 而不是 kube-dns (10.96.0.10)                      │
│ VPC DNS 无法解析 K8s 服务域名                       │
│                                                    │
│ ⚠️  这就是为什么需要在 search domains 中保留        │
│     K8s 域名后缀的原因                              │
└────────────────────────────────────────────────────┘

如果配置了 kube-dns 作为第一个 nameserver:
┌────────────────────────────────────────────────────┐
│ nameserver 10.96.0.10 (kube-dns)                  │
│ nameserver 10.0.0.2                              │
│                                                    │
│ DNS 查询: gitlab.gitlab.svc.cluster.local          │
│ → kube-dns (10.96.0.10)                           │
│ → 返回 Service ClusterIP: 172.21.5.10              │
└───────────────────┬────────────────────────────────┘
                    │ DNS 解析成功
                    ↓
Step 3: 访问 Service ClusterIP
┌────────────────────────────────────────────────────┐
│ 源: 172.24.1.100:56789 (Build 容器 Pod IP)         │
│ 目标: 172.21.5.10:80 (Service ClusterIP)           │
│ 协议: TCP                                          │
└───────────────────┬────────────────────────────────┘
                    │ 离开 Pod 网络命名空间
                    ↓
Step 4: iptables 处理 (节点上)
┌────────────────────────────────────────────────────┐
│ -A PREROUTING -j KUBE-SERVICES                     │
│                                                    │
│ -A KUBE-SERVICES -d 172.21.5.10/32 -p tcp         │
│   --dport 80 -j KUBE-SVC-GITLAB                    │
│                                                    │
│ -A KUBE-SVC-GITLAB                                 │
│   -m statistic --mode random --probability 0.33    │
│   -j KUBE-SEP-GITLAB-POD1                          │
└───────────────────┬────────────────────────────────┘
                    │ 负载均衡选择 Pod
                    ↓
Step 5: DNAT 到后端 Pod
┌────────────────────────────────────────────────────┐
│ -A KUBE-SEP-GITLAB-POD1                            │
│   -j DNAT --to-destination 172.24.2.50:80          │
│                                                    │
│ 修改数据包:                                         │
│ 源: 172.24.1.100:56789                             │
│ 目标: 172.24.2.50:80 (GitLab Pod IP)               │
└───────────────────┬────────────────────────────────┘
                    │ DNAT 完成
                    ↓
Step 6: Pod 间通信 (可能跨节点)
┌────────────────────────────────────────────────────┐
│ 如果同节点:                                         │
│   cni0 → veth → 目标 Pod                           │
│                                                    │
│ 如果跨节点:                                         │
│   flannel.1 (VXLAN 封装)                           │
│   → 节点间通信 (192.168.1.101 → 192.168.1.102)      │
│   → flannel.1 (解封装)                             │
│   → cni0 → veth → 目标 Pod                         │
└────────────────────────────────────────────────────┘
```

---

### 2.3 特殊场景：DinD 临时容器出站流量

```
┌──────────────────────────────────────────────────────────────┐
│  RUN pip install flask (临时容器内执行)                       │
└──────────────────────────────────────────────────────────────┘

Step 1: 临时容器发起 DNS 查询
┌────────────────────────────────────────────────────┐
│ 临时容器 (172.17.0.2 - DinD 内部 IP)                │
│ pip 需要解析 pypi.org                               │
│                                                    │
│ 读取 /etc/resolv.conf:                             │
│   nameserver 10.0.0.2 (继承自 DinD 或 --dns)     │
└───────────────────┬────────────────────────────────┘
                    │ DNS 查询
                    ↓
Step 2: 通过 DinD docker0 网桥
┌────────────────────────────────────────────────────┐
│ 临时容器 eth0 (172.17.0.2)                          │
│ → docker0 网桥 (172.17.0.1)                        │
│ → DinD 容器网络命名空间                             │
└───────────────────┬────────────────────────────────┘
                    │ 离开临时容器网络
                    ↓
Step 3: DinD 容器内 SNAT
┌────────────────────────────────────────────────────┐
│ iptables 规则 (DinD 容器内):                        │
│ -t nat -A POSTROUTING -s 172.17.0.0/16            │
│   ! -o docker0                                     │
│   -j MASQUERADE                                    │
│                                                    │
│ 修改数据包:                                         │
│ 源: 172.24.1.100:12345 (Pod IP)                    │
│ 目标: 10.0.0.2:53                                │
└───────────────────┬────────────────────────────────┘
                    │ 第一次 SNAT
                    ↓
Step 4: 从 Pod 出站
┌────────────────────────────────────────────────────┐
│ Pod eth0 (172.24.1.100)                            │
│ → veth → cni0 网桥                                 │
│ → 节点网络栈                                        │
└───────────────────┬────────────────────────────────┘
                    │ 离开 Pod
                    ↓
Step 5: 节点 SNAT (第二次)
┌────────────────────────────────────────────────────┐
│ iptables 规则 (节点上):                             │
│ -t nat -A POSTROUTING -s 172.24.0.0/16            │
│   ! -o cni0                                        │
│   -j MASQUERADE                                    │
│                                                    │
│ 修改数据包:                                         │
│ 源: 192.168.1.101:12345 (节点 IP)                   │
│ 目标: 10.0.0.2:53                                │
└───────────────────┬────────────────────────────────┘
                    │ 第二次 SNAT
                    ↓
Step 6: 发送到外网
┌────────────────────────────────────────────────────┐
│ 节点网卡 → VPC NAT Gateway → 公网                  │
│ DNS 响应、HTTP 响应原路返回 (反向 SNAT)             │
└────────────────────────────────────────────────────┘

关键点:
- 临时容器的流量经过**两次 SNAT**
  1. DinD docker0 网桥: 172.17.0.2 → 172.24.1.100
  2. Node cni0 网桥: 172.24.1.100 → 192.168.1.101
- 因此临时容器访问外网时，源 IP 最终是**节点 IP**
- 返回流量需要经过两次反向 NAT 才能到达临时容器
```

---

## 三、网络配置的修改与验证

### 3.1 网络初始状态

#### 默认 Pod DNS 配置 (使用 kube-dns)

```yaml
# Pod Spec (默认行为)
apiVersion: v1
kind: Pod
metadata:
  name: test-pod
spec:
  dnsPolicy: ClusterFirst  # 默认值
  # dnsConfig 未设置，自动使用 kube-dns
```

**生成的 /etc/resolv.conf**：
```bash
nameserver 10.96.0.10  # kube-dns Service ClusterIP
search default.svc.cluster.local svc.cluster.local cluster.local
options ndots:5
```

**问题**：
- kube-dns 只解析集群内服务 (*.svc.cluster.local)
- 无法解析外部域名（如 `registry.example.com`）
- 内网环境中 CoreDNS 可能没有配置公网 DNS 转发

---

### 3.2 修改 DNS 配置的方法

#### 方法 1: 修改 Pod Spec (临时方法)

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: test-pod
spec:
  dnsPolicy: None  # 不使用默认 DNS
  dnsConfig:
    nameservers:
      - "10.0.0.2"  # VPC 内部 DNS
      - "10.1.0.251"
      - "10.1.0.252"
    searches:
      - "gitlab.svc.cluster.local"
      - "svc.cluster.local"
      - "cluster.local"
    options:
      - name: ndots
        value: "2"
```

**优点**：
- 直接控制单个 Pod 的 DNS
- 适合临时测试

**缺点**：
- 需要修改每个 Pod 的 Spec
- 不适合 GitLab Runner (Runner Manager 创建的 Pod)

#### 方法 2: GitLab Runner 配置 (推荐)

```toml
# gitlab-runner-values.yaml
runners:
  config: |
    [[runners]]
      executor = "kubernetes"
      [runners.kubernetes]
        # 关键配置：覆盖 Pod 的 DNS
        dns_policy = "none"

        [runners.kubernetes.dns_config]
          nameservers = [
            "10.0.0.2",      # VPC DNS (可访问外网)
            "10.1.0.251",
            "10.1.0.252"
          ]
          searches = [
            "gitlab.svc.cluster.local",
            "svc.cluster.local",
            "cluster.local"
          ]
          [[runners.kubernetes.dns_config.options]]
            name = "ndots"
            value = "2"
```

**Runner 如何应用配置**：
```go
// Runner Manager 创建 Job Pod 时的伪代码
func createJobPod(config RunnerConfig) *corev1.Pod {
    pod := &corev1.Pod{
        Spec: corev1.PodSpec{
            // 应用 dns_policy 配置
            DNSPolicy: corev1.DNSPolicyNone,  // 来自 "none"

            // 应用 dns_config 配置
            DNSConfig: &corev1.PodDNSConfig{
                Nameservers: []string{
                    "10.0.0.2",
                    "10.1.0.251",
                    "10.1.0.252",
                },
                Searches: []string{
                    "gitlab.svc.cluster.local",
                    "svc.cluster.local",
                    "cluster.local",
                },
                Options: []corev1.PodDNSConfigOption{
                    {Name: "ndots", Value: ptr.To("2")},
                },
            },
        },
    }
    return pod
}
```

**优点**：
- 所有 Job Pod 自动应用配置
- 集中管理，易于维护
- 符合 GitOps 最佳实践

**缺点**：
- 需要重新部署 Runner
- 配置错误会影响所有 Job

#### 方法 3: 修改 CoreDNS 配置 (集群级别)

```yaml
# ConfigMap: coredns (kube-system namespace)
apiVersion: v1
kind: ConfigMap
metadata:
  name: coredns
  namespace: kube-system
data:
  Corefile: |
    .:53 {
        errors
        health {
           lameduck 5s
        }
        ready
        kubernetes cluster.local in-addr.arpa ip6.arpa {
           pods insecure
           fallthrough in-addr.arpa ip6.arpa
           ttl 30
        }
        prometheus :9153

        # 添加上游 DNS 服务器（转发外部域名查询）
        forward . 10.0.0.2 10.1.0.251 10.1.0.252

        cache 30
        loop
        reload
        loadbalance
    }
```

**应用配置**：
```bash
kubectl apply -f coredns-config.yaml
kubectl rollout restart deployment coredns -n kube-system
```

**优点**：
- 全局生效，所有 Pod 受益
- 不需要修改 Pod Spec
- 保留 kube-dns 的服务发现能力

**缺点**：
- 影响整个集群
- 需要集群管理员权限
- 配置错误会导致集群范围的 DNS 故障

---

### 3.3 验证网络配置的方法

#### 验证 1: 检查 Pod DNS 配置

```bash
# 查看 Pod 的 DNS 配置
kubectl get pod <pod-name> -n gitlab -o yaml | grep -A 15 dnsPolicy

# 预期输出:
dnsPolicy: None
dnsConfig:
  nameservers:
  - 10.0.0.2
  - 10.1.0.251
  - 10.1.0.252
  searches:
  - gitlab.svc.cluster.local
  - svc.cluster.local
  - cluster.local
  options:
  - name: ndots
    value: "2"
```

#### 验证 2: 检查容器内 /etc/resolv.conf

```bash
# 进入容器检查
kubectl exec -n gitlab <pod-name> -c build -- cat /etc/resolv.conf

# 预期输出:
nameserver 10.0.0.2
nameserver 10.1.0.251
nameserver 10.1.0.252
search gitlab.svc.cluster.local svc.cluster.local cluster.local
options ndots:2
```

#### 验证 3: 测试 DNS 解析

```bash
# 测试外部域名解析
kubectl exec -n gitlab <pod-name> -c build -- \
  nslookup registry.example.com

# 预期输出:
Server:    10.0.0.2
Address 1: 10.0.0.2

Name:      registry.example.com
Address 1: 203.0.113.10

# 测试 K8s 服务解析 (如果配置了 search domains)
kubectl exec -n gitlab <pod-name> -c build -- \
  nslookup gitlab.gitlab.svc.cluster.local

# 如果第一个 DNS 是 VPC DNS，会失败
# 如果第一个 DNS 是 kube-dns，会成功
```

#### 验证 4: 测试网络连通性

```bash
# 测试 DNS 服务器可达性
kubectl exec -n gitlab <pod-name> -c build -- \
  timeout 3 nc -zv 10.0.0.2 53

# 测试镜像仓库可达性
kubectl exec -n gitlab <pod-name> -c build -- \
  curl -v --max-time 10 https://registry.example.com

# 测试 Docker 连接 (DinD)
kubectl exec -n gitlab <pod-name> -c build -- \
  docker -H tcp://docker:2375 info
```

#### 验证 5: 测试完整构建流程

```bash
# 在 Job Pod 中手动执行 docker build
kubectl exec -n gitlab <pod-name> -c build -- sh

# 在容器内:
cat > Dockerfile <<EOF
FROM alpine:latest
RUN apk add --no-cache curl
EOF

docker -H tcp://docker:2375 build -t test:latest .

# 观察输出:
# Step 1/2 : FROM alpine:latest
# latest: Pulling from library/alpine
# ✅ 如果成功拉取，说明 DNS 和网络都正常
```

#### 验证 6: 查看网络流量 (高级)

```bash
# 在 Pod 内抓包
kubectl exec -n gitlab <pod-name> -c build -- \
  tcpdump -i any -nn 'port 53 or port 443' -c 20

# 输出示例:
# 13:45:23.123456 IP 172.24.1.100.54321 > 10.0.0.2.53: DNS query
# 13:45:23.125678 IP 10.0.0.2.53 > 172.24.1.100.54321: DNS response
# 13:45:23.126789 IP 172.24.1.100.54322 > 203.0.113.10.443: HTTPS
```

---

## 四、DNS 问题演进过程 (实际案例)

### 4.1 初始状态：默认 DNS 配置失败

**配置**:
```yaml
# Runner 使用 Kubernetes 默认 DNS (未配置 dns_policy)
# Job Pod 自动使用 dnsPolicy: ClusterFirst
```

**Job Pod 的 /etc/resolv.conf**:
```
nameserver 10.96.0.10  # kube-dns
search gitlab.svc.cluster.local svc.cluster.local cluster.local
options ndots:5
```

**问题现象**:
```bash
$ docker build -t myapp .
#2 ERROR: failed to do request: Head "https://registry.example.com/...":
dial tcp: lookup registry.example.com: i/o timeout
```

**根本原因**:
```
DinD dockerd 进程查询 DNS:
  ↓
读取 /etc/resolv.conf
  ↓
nameserver 10.96.0.10 (kube-dns)
  ↓
DNS 查询: registry.example.com → 10.96.0.10
  ↓
kube-dns (CoreDNS) 收到查询
  ↓
检查：不是 *.svc.cluster.local 域名
  ↓
查找上游 DNS (forward 配置)
  ↓
❌ 未配置上游 DNS 或上游 DNS 不可达
  ↓
超时 (5s)
```

---

### 4.2 第一次尝试：在 DinD 命令中配置 --dns 失败

**方案**:
```yaml
# .gitlab-ci.yml
services:
  - name: docker:dind
    command:
      - "--dns=10.1.0.251"  # 节点主 DNS
      - "--dns=10.1.0.252"  # 节点备 DNS
```

**期望**:
- 让 dockerd 使用节点的 DNS 服务器解析域名

**实际发生**:
```
Job Pod 启动
  ↓
DinD 容器启动
  ↓
dockerd 启动，读取启动参数 --dns
  ↓
--dns 参数存储到 dockerd 配置中
  (用于创建临时容器时设置 DNS)
  ↓
dockerd 自己需要拉取镜像: FROM python:3.9-slim
  ↓
dockerd 进程发起 DNS 查询
  ↓
读取 /etc/resolv.conf (DinD 容器的，来自 Pod)
  ↓
nameserver 10.96.0.10 (kube-dns)
  ↓
❌ --dns 参数对 dockerd 自己无效！
  ↓
DNS 查询失败 (与初始状态相同)
```

**失败原因**:
- `--dns` 参数只影响 **dockerd 创建的容器**
- **不影响** dockerd 进程自己的 DNS 解析
- dockerd 拉取镜像时使用的是容器自己的 `/etc/resolv.conf`

---

### 4.3 第二次尝试：直接配置节点 DNS 失败

**方案**:
```toml
# gitlab-runner-values.yaml (错误配置)
[runners.kubernetes.dns_config]
  nameservers = ["10.1.0.251", "10.1.0.252"]
```

**问题现象**:
```bash
# DinD 容器启动失败
kubectl logs <pod-name> -c docker

# 输出:
time="2025-01-15T10:23:45Z" level=error msg="failed to start daemon"
error="failed to initialize DNS resolver: dial tcp 10.1.0.251:53: i/o timeout"
```

**网络验证**:
```bash
# 从 Pod 测试连接节点 DNS
kubectl run nettest --rm -i --restart=Never \
  --overrides='{
    "spec": {
      "dnsPolicy": "None",
      "dnsConfig": {
        "nameservers": ["10.1.0.251"]
      }
    }
  }' \
  --image=alpine \
  -- timeout 3 nc -zv 10.1.0.251 53

# 输出:
nc: 10.1.0.251 (10.1.0.251:53): Connection timed out

# ❌ Pod 网络无法访问节点内网 DNS
```

**根本原因**:
```
网络架构分析:
┌─────────────────────────────────────────────────┐
│  节点内网网络 (10.0.0.0/16)                    │
│  - 节点 IP: 192.168.1.101                        │
│  - DNS 服务: 10.1.0.251 (不在同一子网)        │
│  - 需要经过路由器到达                            │
└─────────────────────────────────────────────────┘
                     ↑ 路由可达
                     │
┌─────────────────────────────────────────────────┐
│  Pod 网络 (172.24.0.0/16 - Overlay 网络)        │
│  - Pod IP: 172.24.1.100                         │
│  - 通过 CNI 插件与节点网络连接                   │
│  - 只有部分节点网络可达                          │
└─────────────────────────────────────────────────┘
                     ↓ 路由不通
                     ↓
┌─────────────────────────────────────────────────┐
│  其他子网 (10.120.0.0/16)                        │
│  - DNS 服务: 10.1.0.251                       │
│  - Pod 网络没有到此子网的路由                    │
│  - 或防火墙/安全组阻止 Pod 网络访问              │
└─────────────────────────────────────────────────┘

# 检查节点路由表
$ ip route show
default via 10.202.3.1 dev eth0
10.0.0.0/16 dev eth0 proto kernel scope link
10.120.0.0/16 via 10.202.3.1 dev eth0  # 节点可达
172.24.0.0/16 via 192.168.1.101 dev flannel.1  # Pod 网络

# 检查 Pod 路由表
$ kubectl exec <pod> -- ip route show
default via 172.24.1.1 dev eth0
172.24.0.0/16 dev eth0 scope link
# ❌ 没有到 10.120.0.0/16 的路由
```

**失败原因**:
1. **网络隔离**: Pod 网络 (Overlay) 与节点内网 (Underlay) 不在同一网络平面
2. **路由缺失**: Pod 没有到 10.120.0.0/16 子网的路由
3. **安全策略**: 可能有防火墙规则阻止 Pod 访问节点内网服务

---

### 4.4 第三次尝试：测试 VPC 内部 DNS 成功

**灵感来源**:
```bash
# 查看节点的 DNS 配置
$ cat /etc/resolv.conf
nameserver 10.1.0.251  # 主 DNS (Pod 不可达)
nameserver 10.1.0.252  # 备 DNS (Pod 不可达)
nameserver 10.0.0.2    # 第三个 DNS ← 尝试这个！
```

**测试方法**:
```bash
# 创建测试 Pod，使用 10.0.0.2 作为 DNS
kubectl run dns-test --restart=Never \
  --image=alpine \
  --overrides='{
    "spec": {
      "dnsPolicy": "None",
      "dnsConfig": {
        "nameservers": ["10.0.0.2"]
      }
    }
  }' \
  -- nslookup registry.example.com

# 等待 Pod 完成
kubectl wait --for=condition=completed pod/dns-test --timeout=10s

# 查看日志
kubectl logs dns-test

# 输出:
Server:    10.0.0.2
Address:   10.0.0.2:53

Name:      registry.example.com
Address:   203.0.113.10

✅ DNS 解析成功！
```

**网络连通性测试**:
```bash
# 测试从 Pod 到 10.0.0.2 的连通性
kubectl run nettest --rm -i --restart=Never --image=alpine -- \
  timeout 3 nc -zv 10.0.0.2 53

# 输出:
10.0.0.2 (10.0.0.2:53) open
✅ 网络连通！

# 对比测试 (节点 DNS)
kubectl run nettest --rm -i --restart=Never --image=alpine -- \
  timeout 3 nc -zv 10.1.0.251 53

# 输出:
nc: 10.1.0.251 (10.1.0.251:53): Connection timed out
❌ 网络不通
```

**发现原因**:
```
10.0.0.2 的特殊性:
┌─────────────────────────────────────────────────┐
│  阿里云私有化部署的 VPC DNS 服务                 │
│  IP: 10.0.0.2                                 │
│  特点:                                          │
│  - 位于 VPC 网络内                               │
│  - 为 VPC 内所有网络提供 DNS 解析                │
│  - Pod 网络可以访问（有路由规则）                │
│  - 可以解析内网域名和外网域名                    │
│  - 类似于 AWS 的 169.254.169.253               │
└─────────────────────────────────────────────────┘

# 检查 CNI 插件是否配置了到 VPC DNS 的路由
$ kubectl exec <pod> -- ip route get 10.0.0.2
10.0.0.2 via 172.24.1.1 dev eth0 src 172.24.1.100
# ✅ 有路由，可达

$ kubectl exec <pod> -- ip route get 10.1.0.251
RTNETLINK answers: Network is unreachable
# ❌ 无路由，不可达
```

---

### 4.5 最终方案：Runner 配置 VPC DNS 成功

**配置** (`gitlab-runner-values.yaml`):
```toml
[runners.kubernetes]
  dns_policy = "none"  # 不使用 kube-dns

  [runners.kubernetes.dns_config]
    nameservers = [
      "10.0.0.2",      # 🔑 VPC DNS (经验证可用)
      "10.1.0.251",    # 备用 (Pod 不可达，但作为备份)
      "10.1.0.252"     # 备用 (Pod 不可达，但作为备份)
    ]
    searches = [
      "gitlab.svc.cluster.local",
      "svc.cluster.local",
      "cluster.local"
    ]
    [[runners.kubernetes.dns_config.options]]
      name = "ndots"
      value = "2"
```

**应用配置**:
```bash
# 更新 Runner
helm upgrade gitlab-runner gitlab/gitlab-runner \
  --namespace gitlab \
  --version 0.80.0 \
  -f gitlab-runner-values.yaml

# 等待 Runner 重启
kubectl rollout status deployment gitlab-runner -n gitlab

# 触发新的 CI/CD Pipeline
# 在 GitLab UI 中点击 "Run Pipeline"
```

**验证结果**:
```bash
# 查看新创建的 Job Pod
kubectl get pods -n gitlab | grep runner-.*-build

# 检查 DNS 配置
kubectl exec -n gitlab <job-pod-name> -c build -- cat /etc/resolv.conf
nameserver 10.0.0.2
nameserver 10.1.0.251
nameserver 10.1.0.252
search gitlab.svc.cluster.local svc.cluster.local cluster.local
options ndots:2

# 查看 CI/CD 日志
kubectl logs -n gitlab <job-pod-name> -c build -f

# 输出:
Step 1/5 : FROM python:3.9-slim
latest: Pulling from library/python
a803e7c4b030: Pull complete
✅ 镜像拉取成功！

Step 2/5 : COPY . .
✅ 复制代码成功

Step 3/5 : RUN pip install -r requirements.txt
Collecting flask
  Downloading flask-2.3.0-py3-none-any.whl (96 kB)
✅ pip 安装成功 (DNS 解析 pypi.org 成功)

Successfully built abc123def456
Successfully tagged myapp:latest
✅ 完整构建成功！
```

**效果总结**:
| 配置项 | 初始状态 | 最终方案 | 结果 |
|--------|---------|---------|------|
| **DNS 服务器** | 10.96.0.10 (kube-dns) | 10.0.0.2 (VPC DNS) | ✅ 可用 |
| **Pod 可达性** | ✅ 可达 (集群内) | ✅ 可达 (VPC 路由) | ✅ 正常 |
| **解析外部域名** | ❌ 无法解析 | ✅ 成功解析 | ✅ 正常 |
| **解析 K8s 服务** | ✅ 可以 | ⚠️ 需要 search domains | ✅ 保留 |
| **dockerd 拉取镜像** | ❌ 失败 | ✅ 成功 | ✅ 正常 |
| **RUN 指令网络** | ❌ 失败 | ✅ 成功 | ✅ 正常 |

---

## 五、常见问题排查流程

### 5.1 DNS 解析问题排查

```bash
# Step 1: 确认 Pod DNS 配置
kubectl get pod <pod-name> -n gitlab -o yaml | grep -A 10 dnsPolicy

# Step 2: 检查容器 /etc/resolv.conf
kubectl exec -n gitlab <pod-name> -c build -- cat /etc/resolv.conf

# Step 3: 测试 DNS 服务器连通性
kubectl exec -n gitlab <pod-name> -c build -- \
  timeout 3 nc -zv 10.0.0.2 53

# Step 4: 测试 DNS 解析
kubectl exec -n gitlab <pod-name> -c build -- \
  nslookup registry.example.com

# Step 5: 测试 HTTP 连接
kubectl exec -n gitlab <pod-name> -c build -- \
  curl -v --max-time 10 https://registry.example.com
```

### 5.2 网络连通性问题排查

```bash
# Step 1: 检查 Pod IP 和路由
kubectl exec <pod-name> -- ip addr show
kubectl exec <pod-name> -- ip route show

# Step 2: 测试 Pod 到节点网络
kubectl exec <pod-name> -- ping -c 3 192.168.1.101

# Step 3: 测试 Pod 到外网
kubectl exec <pod-name> -- ping -c 3 8.8.8.8

# Step 4: 检查 iptables 规则 (节点上)
ssh node-ip
sudo iptables -t nat -L -n -v | grep KUBE

# Step 5: 检查 CNI 插件日志
kubectl logs -n kube-system -l k8s-app=flannel
```

### 5.3 DinD 专项问题排查

```bash
# Step 1: 查看 DinD 容器日志
kubectl logs <pod-name> -c docker

# Step 2: 检查 dockerd 进程
kubectl exec <pod-name> -c docker -- ps aux | grep dockerd

# Step 3: 测试 Docker 连接
kubectl exec <pod-name> -c build -- \
  docker -H tcp://docker:2375 info

# Step 4: 检查 DinD 网络配置
kubectl exec <pod-name> -c docker -- ip addr show
kubectl exec <pod-name> -c docker -- iptables -t nat -L -n

# Step 5: 测试 DinD 内部网络
kubectl exec <pod-name> -c docker -- \
  docker -H tcp://docker:2375 run --rm alpine ping -c 3 8.8.8.8
```

---

## 六、网络配置最佳实践

### 6.1 DNS 配置策略

#### 场景 1: 内网环境 (本文案例)

```toml
# 推荐配置
dns_policy = "none"
nameservers = [
  "10.0.0.2",  # VPC 内部 DNS (优先)
  "内网DNS1",
  "内网DNS2"
]
searches = [
  "gitlab.svc.cluster.local",
  "svc.cluster.local",
  "cluster.local"
]
```

**优点**:
- ✅ 解析外部域名
- ✅ 保留 K8s 服务发现
- ✅ 符合内网安全策略

**缺点**:
- ⚠️ K8s 服务域名解析较慢 (search domains 遍历)

#### 场景 2: 公网环境

```toml
# 使用默认 kube-dns + 公网 DNS
dns_policy = "ClusterFirst"  # 或不配置

# 确保 CoreDNS 配置了公网 DNS 转发
# kubectl edit cm coredns -n kube-system
forward . 8.8.8.8 1.1.1.1
```

**优点**:
- ✅ K8s 服务解析快速
- ✅ 自动解析外部域名
- ✅ 配置简单

**缺点**:
- ⚠️ 依赖 CoreDNS 配置正确

#### 场景 3: 混合环境

```toml
# 同时支持内网和公网解析
dns_policy = "none"
nameservers = [
  "10.96.0.10",  # kube-dns (K8s 服务优先)
  "10.0.0.2",   # VPC DNS (内网域名)
  "8.8.8.8"       # 公网 DNS (备用)
]
searches = [
  "svc.cluster.local",
  "cluster.local"
]
options = [
  {name = "ndots", value = "2"},
  {name = "timeout", value = "2"}
]
```

**优点**:
- ✅ 全面覆盖所有场景
- ✅ 有备用 DNS

**缺点**:
- ⚠️ DNS 查询可能较慢 (多次尝试)
- ⚠️ 需要确保所有 DNS 都可达

---

### 6.2 网络性能优化

#### 优化 1: 减少跨节点通信

```yaml
# 使用 Pod 亲和性将相关 Pod 调度到同一节点
apiVersion: apps/v1
kind: Deployment
metadata:
  name: gitlab-runner
spec:
  template:
    spec:
      affinity:
        podAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - gitlab
              topologyKey: kubernetes.io/hostname
```

**效果**:
- 减少 VXLAN 封装/解封装开销
- 降低延迟 (1-2ms → 0.1ms)

#### 优化 2: 使用 HostNetwork (谨慎)

```yaml
# Job Pod 使用节点网络 (跳过 CNI)
spec:
  hostNetwork: true
  dnsPolicy: Default  # 使用节点 /etc/resolv.conf
```

**优点**:
- ✅ 性能最佳 (无 Overlay 开销)
- ✅ 直接使用节点 DNS

**缺点**:
- ❌ 安全风险高
- ❌ 端口冲突风险
- ❌ 失去 K8s 网络隔离

**建议**: 仅在极端性能要求下使用

#### 优化 3: 调整 DNS 缓存

```toml
# 增加 DNS 缓存时间
[runners.kubernetes.dns_config.options]
  name = "timeout"
  value = "1"  # 减少 DNS 查询超时时间

# 在应用层缓存 DNS (Python 示例)
import socket
socket.setdefaulttimeout(5)
# 使用 dnspython 库实现本地 DNS 缓存
```

---

### 6.3 安全加固建议

#### 1. 网络策略 (NetworkPolicy)

```yaml
# 限制 Job Pod 只能访问必要的服务
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: gitlab-runner-policy
  namespace: gitlab
spec:
  podSelector:
    matchLabels:
      app: gitlab-runner
  policyTypes:
  - Egress
  egress:
  # 允许访问 kube-dns
  - to:
    - namespaceSelector:
        matchLabels:
          name: kube-system
    ports:
    - protocol: UDP
      port: 53
  # 允许访问 GitLab Server
  - to:
    - podSelector:
        matchLabels:
          app: gitlab
    ports:
    - protocol: TCP
      port: 80
    - protocol: TCP
      port: 443
  # 允许访问镜像仓库 (通过节点出口)
  - to:
    - ipBlock:
        cidr: 0.0.0.0/0
        except:
        - 169.254.169.254/32  # 阻止访问元数据服务
    ports:
    - protocol: TCP
      port: 443
```

#### 2. Pod 安全策略

```yaml
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: gitlab-runner-psp
spec:
  privileged: false  # DinD Service 容器例外
  allowPrivilegeEscalation: false
  requiredDropCapabilities:
  - ALL
  volumes:
  - 'configMap'
  - 'emptyDir'
  - 'projected'
  - 'secret'
  runAsUser:
    rule: 'MustRunAsNonRoot'
  seLinux:
    rule: 'RunAsAny'
  fsGroup:
    rule: 'RunAsAny'
```

#### 3. 镜像仓库认证

```bash
# 使用 ImagePullSecrets 而不是在 CI/CD 中硬编码密码
kubectl create secret docker-registry regcred \
  --docker-server=private-registry.example.com \
  --docker-username=<用户名> \
  --docker-password=<密码> \
  -n gitlab

# 在 Runner 配置中引用
[runners.kubernetes]
  image_pull_secrets = ["regcred"]
```

---

## 七、总结

### 7.1 网络层级关系

```
Layer 0 (物理层): VPC 网络
  ├─ 节点 IP: 10.202.3.x
  ├─ VPC DNS: 10.0.0.2
  └─ NAT Gateway: 出站访问公网
       ↓
Layer 1 (集群层): Kubernetes 网络
  ├─ API Server: 192.168.1.100:6443
  ├─ kube-dns: 10.96.0.10
  └─ CNI 插件: Flannel/Calico
       ↓
Layer 2 (Service 层): ClusterIP / NodePort
  ├─ Service CIDR: 172.21.0.0/16
  ├─ 由 kube-proxy + iptables 实现
  └─ 负载均衡到 Pod IP
       ↓
Layer 3 (Pod 层): Pod 网络
  ├─ Pod CIDR: 172.24.0.0/16
  ├─ 每个节点分配一个 /24 子网
  └─ Pod 内所有容器共享网络命名空间
       ↓
Layer 4 (Container 层): 容器网络
  ├─ 共享 Pod 的 IP、路由、DNS
  ├─ localhost 通信 (同 Pod 容器间)
  └─ eth0 通信 (Pod 间或外部)
       ↓
Layer 5 (DinD 层): Docker-in-Docker 内部网络
  ├─ docker0 网桥: 172.17.0.0/16
  ├─ 临时容器: 172.17.0.x
  ├─ 两次 NAT (docker0 + cni0)
  └─ DNS 继承自 DinD 容器或 --dns 参数
```

### 7.2 关键配置总结

| 配置项 | 配置位置 | 作用对象 | 推荐值 (内网环境) |
|--------|---------|---------|------------------|
| **dns_policy** | gitlab-runner-values.yaml | Job Pod | `none` |
| **dns_config.nameservers** | gitlab-runner-values.yaml | Job Pod 所有容器 | `["10.0.0.2", ...]` |
| **dns_config.searches** | gitlab-runner-values.yaml | Job Pod 所有容器 | `["svc.cluster.local", ...]` |
| **--dns** (DinD) | .gitlab-ci.yml | dockerd 创建的临时容器 | 按需配置 |
| **--insecure-registry** | .gitlab-ci.yml | dockerd | 私有仓库域名 |
| **DOCKER_HOST** | .gitlab-ci.yml | Build 容器 | `tcp://docker:2375` |

### 7.3 数据包流转总结

**出站流量 (Pod → 外部)**:
```
容器应用
  → Pod eth0
  → veth pair
  → cni0 网桥
  → iptables SNAT (Pod IP → 节点 IP)
  → 节点 eth0
  → VPC 网络
  → NAT Gateway
  → 公网
```

**入站流量 (外部 → Pod, NodePort)**:
```
公网
  → 节点 eth0
  → iptables DNAT (节点 IP:NodePort → Pod IP:Port)
  → cni0 网桥
  → veth pair
  → Pod eth0
  → 容器应用
```

**DinD 临时容器出站 (3 层网络)**:
```
临时容器 (172.17.0.x)
  → docker0 网桥
  → iptables SNAT #1 (172.17.0.x → 172.24.1.100)
  → Pod eth0
  → cni0 网桥
  → iptables SNAT #2 (172.24.1.100 → 192.168.1.101)
  → 节点 eth0
  → 外部网络
```

### 7.4 故障排查清单

**DNS 问题**:
- [x] 检查 Pod dnsPolicy 和 dnsConfig
- [x] 检查容器 /etc/resolv.conf
- [x] 测试 DNS 服务器连通性 (nc -zv <dns-ip> 53)
- [x] 测试域名解析 (nslookup <domain>)
- [x] 检查 search domains 配置

**网络连通性问题**:
- [x] 检查 Pod IP 和路由 (ip addr / ip route)
- [x] 测试 Pod 到节点网络 (ping 节点 IP)
- [x] 测试 Pod 到外网 (ping 8.8.8.8)
- [x] 检查 iptables 规则 (节点上)
- [x] 检查 CNI 插件日志

**DinD 问题**:
- [x] 查看 DinD 容器日志 (kubectl logs -c docker)
- [x] 测试 Docker 连接 (docker -H tcp://docker:2375 info)
- [x] 检查 dockerd 启动参数 (ps aux | grep dockerd)
- [x] 检查 DinD 网络配置 (ip addr / iptables)
- [x] 区分 --dns 参数的作用范围

---

**本文档版本**: v2.0
**最后更新**: 2025-01-15
**适用环境**: Kubernetes 1.24+, GitLab Runner 18.x, Docker-in-Docker
